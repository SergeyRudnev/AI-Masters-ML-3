{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UyCGfNgA86kF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "from glob import glob\n",
    "from collections import OrderedDict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import gradcheck\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFaWrLT4GkfY"
   },
   "source": [
    "## 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R930jTYMG6nB"
   },
   "source": [
    "Если вам требуется работать с каким-нибубь набором данных (dataset), то прежде всего проверьте нет ли его среди встроенных наборов данных https://pytorch.org/vision/stable/datasets.html.\n",
    "\n",
    "В текущем домашнем задании мы будем работать с набором данных FashionMNIST. Он присутствует в списке встроенных наборов данных, однако мы воспользуемся реализацией только для удобного и быстрого способа скачать наборы данных. Ниже предлагается реализовать собственный класс для считывания, обработки и упаковки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LauGpMvGF5qr"
   },
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIT32OCMaLLP"
   },
   "source": [
    "Воспользуемся функцией загрузки данных из репозитория наборов данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Fm_cf_hEIapm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte\t   train-images-idx3-ubyte\r\n",
      "t10k-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\r\n",
      "t10k-labels-idx1-ubyte\t   train-labels-idx1-ubyte\r\n",
      "t10k-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\r\n"
     ]
    }
   ],
   "source": [
    "! ls data/FashionMNIST/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-xnY5xk1KBg2"
   },
   "outputs": [],
   "source": [
    "#https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHIlWRV0aZnA"
   },
   "source": [
    "Для удобства PyTorch предоставляет ряд базовых классов `Dataset, DataLoader`, от которых предлагается отнаследоваться при разработке пользовательских классов. Базовый класс `Dataset` используется для загрузки и обработки данных, класс `DataLoader` используется для управления процессом загрузки данных, позволяет в многопоточном режиме загружать данные и упаковывать их.\n",
    "Эти вспомогательные классы находятся в модуле `torch.utils.data`. \n",
    "\n",
    "При наследовании от класса `torch.utils.data.Dataset` требуется переопределить метод `__len__`, который возвращает количество примеров в наборе данных, а также метод `__getitem__`, который позволяет получить доступ к примеру из набора данных по индексу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jf2e5cPbJV2"
   },
   "source": [
    "Реализуем класс для FasionMnist.\n",
    "\n",
    "Элементами датасета должны являться пары '(np.array, int)', массив имеет размерность `(28, 28)`, тип элемента `np.float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "snTBHRTQI1bc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class FashionMnist(Dataset):\n",
    "    def __init__(self, path, train=True, image_transform=None, \n",
    "                 label_transform=None):\n",
    "        if train:\n",
    "            images, labels = load_mnist(os.path.join(path,\"raw\"))\n",
    "        else:\n",
    "            images, labels = load_mnist(os.path.join(path,\"raw\"), kind=\"t10k\")\n",
    "\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        \n",
    "        self.data = list(zip(images.reshape(-1, 28, 28), labels))\n",
    "        \n",
    "        ###########################################################\n",
    "\n",
    "    def __len__(self,):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        ###########################################################\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        ###########################################################\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XVGv_2zBNfpz"
   },
   "outputs": [],
   "source": [
    "test_dataset = FashionMnist(\"data/FashionMNIST\", train=False)\n",
    "train_dataset = FashionMnist(\"data/FashionMNIST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JciETIfndiGR"
   },
   "source": [
    "Визуализируйте случайные элементы набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wBky4UtmOS71"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################################################\n",
    "############# YOUR CODE HERE ##############################\n",
    "\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "320RvzL7PZrI"
   },
   "source": [
    "В конструктор `Dataset` можно передать объект `torchvision.transforms`, который позволяет преобразовать исходные данные. Преобразование `torchvision.transforms.ToTensor` позволяет преобразоать данные из типа `PIL Image` и `numpy.float32` в тип `torch.float32`\n",
    "\n",
    "Реализуйте собственную поддержку преобразований в `FashionMnist`. Проверьте, что приведение типов работает корректно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pQsGbfXUTxcx"
   },
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return torch.from_numpy(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7BpFQ_Y2PoeI"
   },
   "outputs": [],
   "source": [
    "transform = ToTensor()\n",
    "\n",
    "test_dataset = FashionMnist(\"data/FashionMNIST\", \n",
    "                            train=False, \n",
    "                            image_transform=transform, \n",
    "                            label_transform=transform\n",
    "                            )\n",
    "train_dataset = FashionMnist(\"data/FashionMNIST\",\n",
    "                             image_transform=transform, \n",
    "                             label_transform=transform\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ukLn9rY7SCsS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of the data is <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"The type of the data is {type(test_dataset[0][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ltavx0QUMnm"
   },
   "source": [
    "Элементы набора данных могут быть объединены в пакеты (batch) явно и неявно. Если данные могут быть сконкатенированы или обЪединены каким-нибудь тривиальным способом, то можно не передавать никаких дополнительных парамертов в `torch.utils.data.Dataloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Cizxx6m0VAI7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk/Программы/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:149: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return default_collate([torch.as_tensor(b) for b in batch])\n",
      "/home/pk/Программы/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:149: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return default_collate([torch.as_tensor(b) for b in batch])\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=15, num_workers=2, shuffle=True)\n",
    "batch = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SIZiPrBgVwGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the batch is 2\n",
      "The shape of the batch[0] is torch.Size([15, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(f\"The length of the batch is {len(batch)}\")\n",
    "print(f\"The shape of the batch[0] is {batch[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCggRyOQWVIx"
   },
   "source": [
    "Однако, если наша структура данных не позволяет нам использовать объединение по умолчанию, то можно написать собственную функцию, которая будет пакетировать данные. \n",
    "\n",
    "Реализуйте функцию, преобразующую последовательность элементов массива в пакет (batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nQVh93fmWSjA"
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    ###########################################################\n",
    "    ############# YOUR CODE HERE ##############################\n",
    "    imgs = torch.tensor([item[0] for item in batch])\n",
    "    labels = torch.tensor([item[1] for item in batch])\n",
    "    ###########################################################\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wij6F-vpe7KS"
   },
   "source": [
    "Убедитесть, что все работает корректно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4dDtlvlCXNbW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=15, num_workers=2, \n",
    "                             shuffle=True, collate_fn=collate)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=15, num_workers=2,\n",
    "                              shuffle=True, collate_fn=collate)\n",
    "batch = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PFN00IyZXYaF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the batch is 2\n",
      "The shape of the batch[0] is torch.Size([15, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(f\"The length of the batch is {len(batch)}\")\n",
    "print(f\"The shape of the batch[0] is {batch[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHcumwuF86kL"
   },
   "source": [
    "## 2. Реализация модулей нейронной сети (15 баллов)\n",
    "\n",
    "В этом разделе мы полностью реализуем модули для полносвязанной сети. \n",
    "\n",
    "Для начала нам понадобится реализовать прямой и обратный проход через слои. \n",
    "\n",
    "Наши слои будут соответствовать следующему интерфейсу (на примере \"тождественного\" слоя):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzhCW5HcfmKd"
   },
   "source": [
    "Сначала, мы реализуем функцию и её градиент. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rcqeFXxsFGQO"
   },
   "outputs": [],
   "source": [
    "class IdentityFunction(Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jc6Rtczffxv4"
   },
   "source": [
    "Разработанную функцию обернем классом `IdentityLayer`, все слои в `PyTorch` должны быть наследниками базового класса `nn.Module()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SiqeRVcM86kM"
   },
   "outputs": [],
   "source": [
    "class IdentityLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        # An identity layer does nothing\n",
    "        super().__init__()\n",
    "        self.identity = IdentityFunction.apply\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        # An identity layer just returns whatever it gets as input.\n",
    "        return self.identity(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4IoM_pX86kQ"
   },
   "source": [
    "\n",
    "### 2.1 Функция активации ReLU\n",
    "Для начала реализуем функцию активации, слой нелинейности `ReLU(x) = max(x, 0)`. Параметров у слоя нет. Метод `forward` должен вернуть результат поэлементного применения `ReLU` к входному массиву, метод `backward` - градиент функции потерь по входу слоя. В нуле будем считать производную равной 0. Обратите внимание, что при обратном проходе могут понадобиться величины, посчитанные во время прямого прохода, поэтому их стоит сохранить в `ctx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "U9qrJ47xY6H0"
   },
   "outputs": [],
   "source": [
    "class ReLUFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        mask = input > 0\n",
    "        ctx.save_for_backward(mask)\n",
    "        relu = input.clone()\n",
    "        relu[~mask] = 0\n",
    "        ###########################################################\n",
    "        return relu\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        grad_input = grad_output.clone()\n",
    "        mask, = ctx.saved_tensors\n",
    "        grad_input[~mask] = 0\n",
    "        ###########################################################\n",
    "        return grad_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "y09ZVCsT86kT"
   },
   "outputs": [],
   "source": [
    "class ReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        super().__init__()\n",
    "        self.relu = ReLUFunction.apply\n",
    "        ###########################################################\n",
    "    \n",
    "    def forward(self, input):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        ###########################################################\n",
    "        return self.relu(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RwKEUp_V3-L"
   },
   "source": [
    "Не забываем после реализации функции проверить градиент, испльзуя функцию `gradcheck`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "K0RnDQZCXXZn"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "############# YOUR CODE HERE ##############################\n",
    "\n",
    "relu = ReLU()\n",
    "x = torch.randn((5,10), requires_grad = True).double()\n",
    "\n",
    "###########################################################\n",
    "assert gradcheck(relu, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vUmbmR4iXurd"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "############# YOUR CODE HERE ##############################\n",
    "\n",
    "torch_relu = nn.ReLU()\n",
    "our_relu = ReLU()\n",
    "\n",
    "###########################################################\n",
    "\n",
    "assert torch.norm(torch_relu(x.float()) - our_relu(x)) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojTR4GFd86kY"
   },
   "source": [
    "### 2.2 Линейный слой (linear, fully-connected)\n",
    "Далее реализуем полносвязный слой без нелинейности. У слоя два набора параметров: матрица весов (weights) и вектор смещения (bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fBl34oykbcBf"
   },
   "outputs": [],
   "source": [
    "class LinearFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inp, weight, bias):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        output = inp @ weight.T + bias\n",
    "        ctx.save_for_backward(inp, weight, bias)\n",
    "        ###########################################################\n",
    "        return output\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        inp, weight, bias = ctx.saved_tensors\n",
    "        grad_input = grad_output @ weight.data \n",
    "        grad_weight = grad_output.T @ inp.data\n",
    "        grad_bias = grad_output.sum(dim = 0, keepdim = True)\n",
    "        ###########################################################\n",
    "        return grad_input, grad_weight, grad_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "YbN5JOc886kZ"
   },
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, input_units, output_units):\n",
    "        super().__init__()\n",
    "        # initialize weights with small random numbers from normal distribution\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        self.weight = torch.nn.Parameter(\n",
    "            torch.randn(output_units, input_units).double() * 1e-3\n",
    "        )\n",
    "        k = 1/input_units\n",
    "        self.bias = torch.nn.Parameter(torch.rand(1, output_units).double()*(2*np.sqrt(k)) - np.sqrt(k))\n",
    "        self.linear = LinearFunction.apply\n",
    "        ###########################################################\n",
    "        \n",
    "    def forward(self,inp):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        ###########################################################\n",
    "        return self.linear(inp, self.weight, self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gToXI43WYMDv"
   },
   "source": [
    "Проверим градиент, а также сравним с работой нашего модуля с имплементированным в `PyTorch`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "et7mKX5xZfMI"
   },
   "source": [
    "Проверка градиента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "PxLVozqLZb_H"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "############# YOUR CODE HERE ##############################\n",
    "linear = Linear(10,20)\n",
    "x = torch.randn((5,10), requires_grad = True).double()\n",
    "\n",
    "###########################################################\n",
    "assert gradcheck(linear, x, eps = 1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW8ppOciZndN"
   },
   "source": [
    "Сравнение с `PyTorch`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "IIR9svs7Zmq0"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "############# YOUR CODE HERE ##############################\n",
    "torch_linear = nn.Linear(10,20)\n",
    "our_linear = Linear(10,20)\n",
    "weight = torch.randn(20, 10) * 1e-3\n",
    "k = 1/5\n",
    "bias = torch.rand(1,20)*(2*np.sqrt(k)) - np.sqrt(k)\n",
    "###########################################################\n",
    "\n",
    "torch_state_dict = OrderedDict([(\"weight\", weight), (\"bias\", bias.reshape(-1))])\n",
    "our_state_dict = OrderedDict([(\"weight\", weight), (\"bias\", bias)])\n",
    "torch_linear.load_state_dict(torch_state_dict)\n",
    "our_linear.load_state_dict(our_state_dict)\n",
    "\n",
    "###########################################################\n",
    "############# YOUR CODE HERE ##############################\n",
    "assert torch.norm(torch_linear(x.float()) - our_linear(x)) < 1e-5\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dyhDg0D86kt"
   },
   "source": [
    "### 2.3 LogSoftmax (Log + Softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArL0HLGH86ku"
   },
   "source": [
    "Для решения задачи многоклассовой классификации обычно используют `softmax` в качестве нелинейности на последнем слое, чтобы получить \"оценку\" вероятности классов для каждого объекта:$$\\hat y = softmax(x)  = \\bigl \\{\\frac {exp(x_i)}{\\sum_j exp(x_j)} \\bigr \\}_{i=1}^K, \\quad K - \\text{число классов}$$В этом случае удобно оптимизировать логарифм правдоподобия:$$L(y, \\hat y) = -\\sum_{i=1}^K y_i \\log \\hat y_i \\rightarrow \\min,$$где $y_i=1$, если объект принадлежит $i$-му классу, и 0 иначе. Записанная в таком виде, эта функция потерь совпадает с выражением для кросс-энтропии. Очевидно, что ее также можно переписать через индексацию, если через $y_i$ обозначить класс данного объекта:$$L(y, \\hat y) = - \\log \\hat y_{y_i} \\rightarrow \\min$$В таком виде ее удобно реализовывать.\n",
    "\n",
    "Реализуйте слой `LogSoftmax` (без параметров). Метод `forward` должен вычислять логарифм от `softmax`, а метод `backward` - пропускать градиенты. В общем случае в промежуточных вычислениях `backward` получится трехмерный тензор, однако для нашей конкретной функции потерь все вычисления можно реализовать в матричном виде. Поэтому мы будем предполагать, что аргумент `grad_output` - это матрица, у которой в каждой строке только одно ненулевое значение (не обязательно единица).\n",
    "\n",
    "Комментарий: разобраться `Log-Sum-Exp trick`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "xSV3XD0N86ky"
   },
   "outputs": [],
   "source": [
    "class LogSoftmaxFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inp):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        c = inp.max(dim = 1, keepdim = True).values\n",
    "        ctx.save_for_backward(c, inp)\n",
    "        logsumexp = (torch.log(torch.exp(inp - c).sum(dim = 1, keepdim = True)))\n",
    "        return inp - c - logsumexp\n",
    "        ###########################################################\n",
    "    \n",
    "    @staticmethod        \n",
    "    def backward(ctx, grad_output):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        c, inp = ctx.saved_tensors\n",
    "        \n",
    "        # так как считаем, что в каждой строчке матрицы grad_output только одно ненудевое значение, \n",
    "        # то можно уменьшить размерность этой матрицы, просуммировав элементы по строчкам\n",
    "        \n",
    "        reduced_grad_output = torch.sum(grad_output, dim = 1, keepdim = True)\n",
    "        softmax = torch.exp(inp - c) / torch.exp(inp - c).sum(dim = 1, keepdim = True)\n",
    "        grad_input = grad_output - softmax * reduced_grad_output # раскрыли скобки в градиенте, умножив grad_output на единичную матрицу\n",
    "        return grad_input\n",
    "        ###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "z7OnC6o_z2vg"
   },
   "outputs": [],
   "source": [
    "class LogSoftmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        self.logsoftmax = LogSoftmaxFunction.apply\n",
    "        ###########################################################\n",
    "\n",
    "    def forward(self, input):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        return self.logsoftmax(input)\n",
    "        ###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ke4G67cddjVA"
   },
   "source": [
    "Проверка градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsoftmax = LogSoftmax()\n",
    "x = torch.randn((5,10), requires_grad = True).double()\n",
    "\n",
    "###########################################################\n",
    "assert gradcheck(logsoftmax, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "cfgkVgGbrQEv"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "############# YOUR CODE HERE ##############################\n",
    "\n",
    "torch_logsoftmax = nn.LogSoftmax(dim = 1)\n",
    "our_logsoftmax = LogSoftmax()\n",
    "x = torch.randn((5,10), requires_grad = True)\n",
    "assert torch.norm(torch_logsoftmax(x.float()) - our_logsoftmax(x)) < 1e-5\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Sn2M_Q086k2"
   },
   "source": [
    "### 2.4 Dropout\n",
    "Реализуйте слой Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "qCLECy1y86k3"
   },
   "outputs": [],
   "source": [
    "class DropoutFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inp, p):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        distr = torch.ones(inp.size()) * (1 - p)\n",
    "        samples = torch.bernoulli(distr)\n",
    "        normalizing_const = torch.tensor((1 / (1 - p)), dtype = torch.double)\n",
    "        out = inp * samples * normalizing_const\n",
    "        ctx.save_for_backward(samples, normalizing_const)\n",
    "        return out\n",
    "        ###########################################################\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        samples, normalizing_const = ctx.saved_tensors\n",
    "        grad_input = samples * normalizing_const * grad_output\n",
    "    \n",
    "        return grad_input, None\n",
    "        ###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "pS5z_mth1ZAZ"
   },
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super().__init__()\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        self.p = p\n",
    "        self.dropout = DropoutFunction.apply\n",
    "        ###########################################################\n",
    "        \n",
    "    def forward(self, input):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        if self.training:\n",
    "            return self.dropout(input, self.p)\n",
    "        else:\n",
    "            return self.dropout(input, self.p) * (1 - self.p)\n",
    "        ###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyPPzkCI86k7"
   },
   "source": [
    "### 2.5 CrossEntropy\n",
    "\n",
    "При решении задачи многоклассовой классификации мы будет использовать в качестве функции потерь кроссэнтропию. Реализуйте функцию потерь. В разделе 2.3 приведены полезные формулы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "KotXWXnT3-j5"
   },
   "outputs": [],
   "source": [
    "class CrossEntropyFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, activations, target):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        ctx.save_for_backward(activations, target)\n",
    "        # activations - результат применения logsoftmax, то есть матрица по строчкам которой логарифмы вероятностей принадлежности к классам \n",
    "        # выбираем логарифм вероятности для каждого объекта, соответствующий принадлежности к его истинному классу, \n",
    "        # а потом берём среднее с обратным знаком(так как это ошибка и мы её хотим минимизировать) по всем объектам\n",
    "        return -activations[range(len(target)), target].mean()    \n",
    "        ###########################################################\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        activations, target = ctx.saved_tensors\n",
    "        grad = torch.zeros(activations.shape)\n",
    "        grad[range(len(target)), target] = -1/activations.shape[0]\n",
    "        grad_input = grad * grad_output\n",
    "        return grad_input, None\n",
    "        ###########################################################\n",
    "\n",
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        self.crossentropy = CrossEntropyFunction.apply\n",
    "        ###########################################################\n",
    "\n",
    "    def forward(self, activations, target):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        return self.crossentropy(activations, target)\n",
    "        ###########################################################  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randint(10, (5,), dtype=torch.int64)\n",
    "our_crossentropy = CrossEntropy()\n",
    "logsoftmax = LogSoftmax()\n",
    "x = torch.randn((5,10), requires_grad = True)\n",
    "logpredictions = logsoftmax(x)\n",
    "# заметим, что nn.functional.cross_entropy(logpredictions, target) = nn.functional.cross_entropy(x, target)\n",
    "assert torch.norm(nn.functional.cross_entropy(logpredictions, target) - our_crossentropy(logpredictions, target)) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFNcOfVNesCC"
   },
   "source": [
    "Проверка градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "lXQr7sllKi8k"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "############# YOUR CODE HERE ##############################\n",
    "logsoftmax = LogSoftmax()\n",
    "target = torch.randint(10, (5,), dtype=torch.int64)\n",
    "crossentropy = CrossEntropy()\n",
    "x = torch.randn((5,10), requires_grad = True).double()\n",
    "logpredictions = logsoftmax(x)\n",
    "assert gradcheck(crossentropy, (logpredictions, target))\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmzKDpyE86lg"
   },
   "source": [
    "## 3. Сборка и обучение нейронной сети (5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPqlZfj_86lg"
   },
   "source": [
    "Реализуйте произвольную нейросеть, состоящую из ваших блоков. Она должна состоять из нескольких полносвязанных слоев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, input_size, output_size, relu=True, dropout=True, p = 0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = Linear(input_size, output_size)\n",
    "        self.relu = ReLU() if relu else nn.Identity()\n",
    "        self.dropout = Dropout(p) if dropout else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.linear(x)\n",
    "        y2 = self.relu(y1)\n",
    "        y3 = self.dropout(y2)\n",
    "        return y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tkESXVD87sM8"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size=28*28, hidden_layers_size=32, num_layers=5,\n",
    "                 num_classes=10):\n",
    "        super().__init__()\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "    \n",
    "        layers = [nn.Flatten(), Block(input_size, hidden_layers_size, relu = True, dropout = False)]\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            layers.append(Block(hidden_layers_size, hidden_layers_size, relu = True, dropout = True))\n",
    "            \n",
    "        layers.append(Block(hidden_layers_size, num_classes, relu = False, dropout = False))\n",
    "        \n",
    "        layers.append(LogSoftmax())\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "       \n",
    "        ###########################################################\n",
    "\n",
    "    def forward(self, inp):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        return self.net(inp.double())\n",
    "        ###########################################################\n",
    "    def predict(self, inp):\n",
    "        ###########################################################\n",
    "        ############# YOUR CODE HERE ##############################\n",
    "        res = self.net(inp.double())\n",
    "        return res.argmax(dim = 1)\n",
    "        ###########################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vj-eEvMFfbSo"
   },
   "source": [
    "Ниже приведены функции, реализующие обучение нейронной сети. В данном задании их предлагается просто переиспользовать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "vDhcoCB4OpXE"
   },
   "outputs": [],
   "source": [
    "class EmptyContext:\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "8AsWblqIOquI"
   },
   "outputs": [],
   "source": [
    "# accuract metric for our classififcation\n",
    "def accuracy(model_labels, labels):\n",
    "    return torch.mean((model_labels == labels).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Oy33FHuv_Us-"
   },
   "outputs": [],
   "source": [
    "def perform_epoch(model, loader, criterion, \n",
    "                optimizer=None, device=None):\n",
    "    is_train = optimizer is not None\n",
    "    model = model.to(device)\n",
    "    if is_train:  \n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_n = 0\n",
    "    with EmptyContext() if is_train else torch.no_grad():\n",
    "        for batch_data, batch_labels in loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.to(device) \n",
    "            model_labels = model(batch_data)\n",
    "            model_prediction = model.predict(batch_data)\n",
    "            batch_labels = batch_labels.to(torch.int64)\n",
    "            new_loss = criterion(model_labels, batch_labels)\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                new_loss.backward()\n",
    "                optimizer.step() \n",
    "\n",
    "            one_batch_loss = float(criterion(model_labels, batch_labels))\n",
    "            one_batch_acc = accuracy(model_prediction, batch_labels)\n",
    "            \n",
    "            total_loss += one_batch_loss\n",
    "            total_acc += one_batch_acc\n",
    "            total_n += 1 \n",
    "    return (total_loss / total_n, total_acc / total_n) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtamPEJZgOY5"
   },
   "source": [
    "Теперь обучим нашу нейронную сеть. В данном разделе будем использовать оптимизатор `Adam` с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "mEcyUJJI_aAn"
   },
   "outputs": [],
   "source": [
    "model     = Network()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = CrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "OBADDSi0_jx7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss 1.4559177421756282, accuracy 0.3891849219799042\n",
      "Current learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss 1.199940356858684, accuracy 0.4895666539669037\n",
      "Current learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss 1.1322998690060364, accuracy 0.5173488259315491\n",
      "Current learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 : loss 1.1533510198879584, accuracy 0.5161823630332947\n",
      "Current learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 : loss 1.155807482731561, accuracy 0.52036452293396\n",
      "Current learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 5 : loss 1.2081366980989559, accuracy 0.4903692603111267\n",
      "Current learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 6 : loss 1.2009869271250408, accuracy 0.4892999827861786\n",
      "Current learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 7 : loss 1.1745739404553381, accuracy 0.5145983099937439\n",
      "Current learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 8 : loss 1.218427773506033, accuracy 0.5102660655975342\n",
      "Current learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 9 : loss 1.1860476864790281, accuracy 0.5105156302452087\n",
      "Current learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss, acc = perform_epoch(model, train_dataloader, criterion, \n",
    "                                optimizer=optimizer, device=device)\n",
    "    print(f\"Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
    "    print(f\"Current learning rate: {optimizer.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "JxrvNtm3YSJn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 9 : loss 1.1860476864790281, accuracy 0.5105156302452087\n",
      "Current learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "print(f\"Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
    "print(f\"Current learning rate: {optimizer.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WS41CQj0Y6Q8"
   },
   "source": [
    "Дальше:\n",
    "- Проведите эксперименты с числом слоев. \n",
    "- Постройте графики зависимости качества модели на тренировочной и тестовой выборках от числа слоев. Для получения статистически значимых результатов повторите эксперименты несколько раз.\n",
    "- Сделайте выводы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 0.8830415997189179, accuracy train 0.6573231220245361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 0.7060119628116155, accuracy train 0.7480982542037964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 0.6721723445998279, accuracy train 0.7635999321937561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  0.7558019667083894 accuracy test  tensor(0.7291)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.00335831895505, accuracy train 0.6052021384239197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 0.7887186809643015, accuracy train 0.7156121134757996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 0.7526170360107716, accuracy train 0.7341979742050171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 : loss train 0.7303140173087299, accuracy train 0.7423983812332153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 : loss train 0.730499476555879, accuracy train 0.7466489672660828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  0.8091796806132837 accuracy test  tensor(0.7216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 0.8472824878306938, accuracy train 0.6696920990943909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 0.6981168753628789, accuracy train 0.7431157231330872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 0.675741168942026, accuracy train 0.7595992684364319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 : loss train 0.6631882047965059, accuracy train 0.76741623878479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 : loss train 0.6375503720933531, accuracy train 0.7780348658561707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 5 : loss train 0.6252288166311035, accuracy train 0.7822680473327637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 6 : loss train 0.6196152749144278, accuracy train 0.7845660448074341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 7 : loss train 0.6020412982993462, accuracy train 0.7979678511619568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 8 : loss train 0.6013274708718818, accuracy train 0.7964011430740356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 9 : loss train 0.5987352954252994, accuracy train 0.7967840433120728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      " 20%|████████▊                                   | 1/5 [04:06<16:27, 246.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  0.6691758955848379 accuracy test  tensor(0.7827)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.1378217244109121, accuracy train 0.5185452699661255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 0.9346579057571236, accuracy train 0.6104685664176941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 0.9102981209885905, accuracy train 0.6266032457351685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  1.2425857050627633 accuracy test  tensor(0.4902)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.3801090380854044, accuracy train 0.42796626687049866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 1.0961744026432523, accuracy train 0.5305808782577515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 1.061402166984586, accuracy train 0.5434309840202332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 : loss train 1.0239919080249322, accuracy train 0.5599806904792786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 : loss train 1.022826481515917, accuracy train 0.5651648640632629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  1.3368951120999641 accuracy test  tensor(0.4270)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.2081003036418958, accuracy train 0.49639594554901123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 0.9801318044116518, accuracy train 0.6128356456756592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 0.9379491077640448, accuracy train 0.6421876549720764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 : loss train 0.9213201800991837, accuracy train 0.6498891711235046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 : loss train 0.9009210278379324, accuracy train 0.6575567126274109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 5 : loss train 0.903756261679017, accuracy train 0.6644905209541321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 6 : loss train 0.9015644624600552, accuracy train 0.6658404469490051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 7 : loss train 0.884336340743345, accuracy train 0.6761084198951721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 8 : loss train 0.8639504683080902, accuracy train 0.686259388923645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 9 : loss train 0.8577321657583139, accuracy train 0.6861262917518616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      " 40%|█████████████████▌                          | 2/5 [08:56<13:36, 272.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  1.1911551470846349 accuracy test  tensor(0.5135)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.3651542204754192, accuracy train 0.43678268790245056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 1.0862606268313562, accuracy train 0.5496472716331482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 1.0423419650898638, accuracy train 0.5710151791572571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  1.6084282586812106 accuracy test  tensor(0.3506)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.4931254135690735, accuracy train 0.3672538101673126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 1.2576059913952744, accuracy train 0.44038692116737366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 1.2298312198218135, accuracy train 0.4466703534126282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 : loss train 1.226520319595855, accuracy train 0.4524030387401581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 : loss train 1.2158578817914814, accuracy train 0.4546363651752472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  1.633260749251859 accuracy test  tensor(0.3195)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.3601910729577735, accuracy train 0.4353152811527252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 1.0901284278446977, accuracy train 0.5590991973876953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 1.0460655036535342, accuracy train 0.5786985754966736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 : loss train 1.0157890669316814, accuracy train 0.5887171626091003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 : loss train 1.0390801824999032, accuracy train 0.572950005531311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 5 : loss train 0.9752396115584494, accuracy train 0.5984342694282532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 6 : loss train 0.980266774825705, accuracy train 0.6030002236366272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 7 : loss train 1.0432921152733594, accuracy train 0.5798848867416382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 8 : loss train 1.0215232374482899, accuracy train 0.5897835493087769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 9 : loss train 0.9842573138832547, accuracy train 0.5939662456512451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      " 60%|██████████████████████████▍                 | 3/5 [14:26<09:56, 298.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  1.4772207575038543 accuracy test  tensor(0.3861)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.7243132572371547, accuracy train 0.29066991806030273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 1.5640723139130048, accuracy train 0.3380714952945709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 1.5037935017559816, accuracy train 0.3612719476222992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  2.1663690521786965 accuracy test  tensor(0.1297)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.855886957638954, accuracy train 0.254902184009552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 1.5445883439306742, accuracy train 0.35788798332214355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 1.3838176790401684, accuracy train 0.41365522146224976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 : loss train 1.3502221683663402, accuracy train 0.43613773584365845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 : loss train 1.321945876808143, accuracy train 0.4405714273452759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  2.0923077954956364 accuracy test  tensor(0.2317)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.414605745467091, accuracy train 0.40645042061805725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 1.1191082476770708, accuracy train 0.5244979858398438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 1.0838777609796524, accuracy train 0.5520812273025513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 : loss train 1.0577681847616105, accuracy train 0.5727322101593018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 : loss train 1.0571410439055855, accuracy train 0.5748661160469055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 5 : loss train 1.0774542224774168, accuracy train 0.5674648284912109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 6 : loss train 1.0399154698845976, accuracy train 0.5827658772468567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 7 : loss train 1.0611646552185, accuracy train 0.586764931678772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 8 : loss train 1.0391128123634008, accuracy train 0.5997841954231262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 9 : loss train 1.0661725965459898, accuracy train 0.5824999213218689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      " 80%|███████████████████████████████████▏        | 4/5 [20:43<05:29, 329.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  1.8019744798759771 accuracy test  tensor(0.2642)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.478959737065554, accuracy train 0.38988471031188965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 1.1812798249823806, accuracy train 0.5037994980812073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 1.1436661665320136, accuracy train 0.5222644209861755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  2.1080618033087384 accuracy test  tensor(0.1790)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.4617242310281018, accuracy train 0.378185510635376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 1.2028664049708262, accuracy train 0.4861501455307007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 1.1557467159314105, accuracy train 0.5046659111976624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 : loss train 1.1280264042712553, accuracy train 0.5156986117362976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 : loss train 1.0930534012367856, accuracy train 0.5356314778327942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  2.0824296810336382 accuracy test  tensor(0.1944)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 : loss train 1.7976489698926075, accuracy train 0.2569683790206909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 : loss train 1.541177702386588, accuracy train 0.3091873526573181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 : loss train 1.503489997123665, accuracy train 0.3288709819316864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 : loss train 1.466773264597826, accuracy train 0.33720487356185913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 : loss train 1.4658486377899247, accuracy train 0.3406214714050293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 5 : loss train 1.4887534259852777, accuracy train 0.3414050042629242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 6 : loss train 1.4345933358585983, accuracy train 0.3486883044242859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 7 : loss train 1.4064961730333045, accuracy train 0.3614054024219513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 8 : loss train 1.447687445777718, accuracy train 0.3572882413864136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 9 : loss train 1.541171431258324, accuracy train 0.3426711857318878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "/tmp/ipykernel_72641/73920298.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  imgs = torch.tensor([item[0] for item in batch])\n",
      "100%|████████████████████████████████████████████| 5/5 [27:36<00:00, 331.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test  2.2592379338322037 accuracy test  tensor(0.1593)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_layers = [1,2,3,4,5]\n",
    "number_of_epoches = [3,5,10] \n",
    "Mean_Accuracy_Train = []\n",
    "Mean_Accuracy_Test = []\n",
    "for i in tqdm(number_of_layers):\n",
    "    Accuracy_Train = []\n",
    "    Accuracy_Test = []\n",
    "    for epoches in number_of_epoches:\n",
    "        \n",
    "        model     = Network(num_layers = i)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        criterion = CrossEntropy()\n",
    "\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        for epoch in range(epoches):\n",
    "            loss_train, acc_train = perform_epoch(model, train_dataloader, criterion, \n",
    "                                optimizer=optimizer, device=device)\n",
    "            print(f\"Epoch - {epoch} : loss train {loss_train}, accuracy train {acc_train}\")\n",
    "            \n",
    "        Accuracy_Train.append(acc_train)\n",
    "        \n",
    "        loss_test, acc_test = perform_epoch(model, test_dataloader, criterion, \n",
    "                            optimizer=None, device=device)\n",
    "        print(\"loss test \", loss_test, \"accuracy test \", acc_test)\n",
    "        Accuracy_Test.append(acc_test)\n",
    "    \n",
    "    Mean_Accuracy_Train.append(np.mean(Accuracy_Train))\n",
    "    Mean_Accuracy_Test.append(np.mean(Accuracy_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 780x520 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (6, 4), dpi = 130)\n",
    "plt.plot(number_of_layers, Mean_Accuracy_Train, label='Train')\n",
    "plt.plot(number_of_layers, Mean_Accuracy_Test, label='Test')\n",
    "plt.xticks([1,2,3,4,5])\n",
    "plt.xlabel(\"Number of layers\")\n",
    "plt.title(\"Mean Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно графикам можно сделать следующие выводы:\n",
    "    Во-первых, с увеличением числа слоёв модель становися более сложной, поэтому ей требуется больше эпох для обучения. Во-вторых, среди выбранного диапазона количества слоёв лучшее качество показала модель с наименьшим числом слоёв из рассматривыемых. Возможно, более сложные модели(с большим числом слоёв) недообучились, либо для решения конкретной задачи больше подходят более простые модели, либо мы не дошли до оптимального числа слоёв в силу небольшого диапазона."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3vcONKQ86mu"
   },
   "source": [
    "## 4. Бонусная часть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kuhxy7aW86mu"
   },
   "source": [
    "### 4.1 Реализация метода оптимизации (3 + 3 балла).\n",
    "Реализуйте сами метод оптимизации  для рассмотренной выше архитектуры. Вы можете выбрать произвольный метод от градиентного спуска до современных вариантов. Продемонстрируйте правильную работу метода оптимизации, сравните его работы с Adam. \n",
    "\n",
    "**Дополнительные баллы** вы получите, если метод будет уникален среди сдавших задание. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYMu0uF1p6o0"
   },
   "outputs": [],
   "source": [
    "class SotaOptimizer(Optimizer):\n",
    "    def __init__(self, params, lr=1e-3):\n",
    "        defaults = dict(lr=lr)\n",
    "        super(SotaOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(SotaOptimizer, self).__setstate__(state)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self,):\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr']\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None:\n",
    "                    p.data.add_(-lr*p.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3aabYCykXL7"
   },
   "source": [
    "### 4.2 Реализация современной функции активации (2 + 2 балла).\n",
    "Реализуйте одну из активаций, предложенных на лекции или в статье. Например, `Hardswish`. Сравните сеть с вашей активацией и с `ReLU`. \n",
    "\n",
    "**Дополнительные баллы** вы получите, если функция будет уникальна среди сдавших задание. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
